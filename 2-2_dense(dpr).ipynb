{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dense retrieval\n",
    "\n",
    "작성일자: 210119\\\n",
    "작성자: 조진욱\\\n",
    "목표: \n",
    "1. 2-1 에서 Sparse 임베딩 모델(TFIDF) 대신 Dense 임베딩 모델(DPR) 을 사용해보자\\\n",
    "2. FAISS, datasets 패키지를 이용해서 retrieval 과정을 만들어보자\n",
    "순서: \n",
    "2-1과 동일\n",
    "\n",
    "다만 2-1 의 retrieval 결과와 성능을 비교할 예정\n",
    "\n",
    "비고:\n",
    "1. DPR, faiss 와 datasets 를 그대로 사용한 예시라서 매우 쉽게 짜여져있음\n",
    "교육을 위해서는 어느정도 구현을 할 수 있도록 만들어 둬야함\n",
    "2. \n",
    "\n",
    "TO DO:\n",
    "1. batch 과정이 어려울 것 같으면 처음엔 batch 1 로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(documents: dict, ctx_encoder: DPRContextEncoder, ctx_tokenizer: DPRContextEncoderTokenizerFast) -> dict:\n",
    "    \"\"\"Compute the DPR embeddings of document passages\"\"\"\n",
    "    input_ids = ctx_tokenizer(\n",
    "        documents[\"title\"], documents[\"text\"], truncation=True, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    embeddings = ctx_encoder(input_ids.to(device=device), return_dict=True).pooler_output\n",
    "    return {\"embeddings\": embeddings.detach().cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dpr_ctx_encoder_model_name = \"facebook/dpr-ctx_encoder-multiset-base\"\n",
    "rag_model_name = \"facebook/rag-sequence-nq\"\n",
    "batch_size = 16\n",
    "root_data_dir = \"./data\"\n",
    "data_dir = \"./data/squad_odqa\"\n",
    "output_dir = \"./data/dense\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dpr 용 csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab96e5aaea604eef869c3a6f62e5c699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "38708\n"
     ]
    }
   ],
   "source": [
    "with open(f'{root_data_dir}/squad/dev.json', 'r') as reader:\n",
    "    input_data = json.load(reader)['data']\n",
    "\n",
    "is_training = True\n",
    "row_list = []\n",
    "\n",
    "count = 0\n",
    "ctx_count = 0 \n",
    "for doc_id, entry in enumerate(tqdm(input_data)):\n",
    "    title = entry[\"title\"]\n",
    "    for paragraph in entry[\"paragraphs\"]:\n",
    "        context_text = paragraph[\"context\"]\n",
    "        \n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            qas_id = qa[\"id\"]\n",
    "            question_text = qa[\"question\"]\n",
    "            start_position_character = None\n",
    "            answer_text = None\n",
    "            answers = []\n",
    "\n",
    "            is_impossible = qa.get(\"is_impossible\", False)\n",
    "            if not is_impossible:\n",
    "                if is_training:\n",
    "                    answer = qa[\"answers\"][0]\n",
    "                    answer_text = answer[\"text\"]\n",
    "                    start_position_character = answer[\"answer_start\"]\n",
    "                else:\n",
    "                    answers = qa[\"answers\"]\n",
    "                    \n",
    "            temp = {\n",
    "                'title':title,\n",
    "                'text':context_text,\n",
    "                'question':question_text,\n",
    "                'answer':answer_text,\n",
    "                'title_id':doc_id,\n",
    "                'ctx_id': ctx_count,\n",
    "                'question_id': count\n",
    "            }\n",
    "            row_list.append(temp)\n",
    "            count += 1\n",
    "        ctx_count += 1\n",
    "\n",
    "print(len(row_list))\n",
    "df = pd.DataFrame(row_list)\n",
    "df.to_csv(f\"{output_dir}/train_tcqaidx.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 datasets 패키지 이용해서 데이터 로드 및 데이터셋 구축\n",
    "https://huggingface.co/docs/datasets/loading_datasets.html?highlight=csv#csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Features, Sequence, Value, load_dataset\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-1a69b9128733c8f4 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-1a69b9128733c8f4/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-1a69b9128733c8f4/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"csv\", data_files=[f\"{output_dir}/train_tc.csv\"], split=\"train\", delimiter=\"\\t\", column_names=[\"title\", \"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_text(text: str, n=100, character=\" \") -> List[str]:\n",
    "    \"\"\"Split the text every ``n``-th occurrence of ``character``\"\"\"\n",
    "    text = text.split(character)\n",
    "    return [character.join(text[i : i + n]).strip() for i in range(0, len(text), n)]\n",
    "\n",
    "def split_documents(documents: dict) -> dict:\n",
    "    \"\"\"Split documents into passages\"\"\"\n",
    "    titles, texts = [], []\n",
    "    for title, text in zip(documents[\"title\"], documents[\"text\"]):\n",
    "        if text is not None:\n",
    "            for passage in split_text(text):\n",
    "                titles.append(title if title is not None else \"\")\n",
    "                texts.append(passage)\n",
    "    return {\"title\": titles, \"text\": texts}\n",
    "\n",
    "dataset = dataset.map(split_documents, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_encoder = DPRContextEncoder.from_pretrained(dpr_ctx_encoder_model_name).to(device=device)\n",
    "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(dpr_ctx_encoder_model_name)\n",
    "new_features = Features(\n",
    "    {\"text\": Value(\"string\"), \"title\": Value(\"string\"), \"embeddings\": Sequence(Value(\"float32\"))}\n",
    ")  # optional, save as float32 instead of float64 to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97209668968b4e35a25a27884c97483e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=850.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    partial(embed, ctx_encoder=ctx_encoder, ctx_tokenizer=ctx_tokenizer),\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    features=new_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_path = os.path.join(output_dir, \"my_knowledge_dataset\")\n",
    "dataset.save_to_disk(passages_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 index the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87dc9081ca44aa483d10eafe57a6c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'title', 'embeddings'],\n",
       "    num_rows: 13598\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === index config ===\n",
    "dim = 768 # The dimension of the embeddings to pass to the HNSW Faiss index.\n",
    "num = 128 # The number of bi-directional links created for every new element during the HNSW index construction.\n",
    "\n",
    "index = faiss.IndexHNSWFlat(dim, num, faiss.METRIC_INNER_PRODUCT)\n",
    "dataset.add_faiss_index(\"embeddings\", custom_index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index\n",
    "index_path = os.path.join(output_dir, \"my_knowledge_dataset_hnsw_index.faiss\")\n",
    "dataset.get_index(\"embeddings\").save(index_path)\n",
    "# dataset.load_faiss_index(\"embeddings\", index_path)  # to reload the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagRetriever, RagTokenizer, RagSequenceForGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RagRetriever.from_pretrained(\n",
    "    rag_model_name, index_name=\"custom\", indexed_dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Where did Greece culture begin?\"\n",
    "question = \"What do neuroanatomists study?\" # 10761 doc expected, 55th title\n",
    "input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_hidden_states = model.question_encoder(input_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input_ids = model.retriever(\n",
    "    input_ids,\n",
    "    question_hidden_states.cpu().detach().to(torch.float32).numpy(),\n",
    "    prefix=model.generator.config.prefix,\n",
    "    n_docs=2,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"context_input_ids\"]\n",
    "\n",
    "# set to correct device\n",
    "context_input_ids = context_input_ids.to(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_doc_embeds, doc_ids, doc_dicts = retriever.retrieve(question_hidden_states.cpu().detach().to(torch.float32).numpy(),\n",
    "                                                              n_docs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_doc_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3609, 3611, 4742]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings', 'text', 'title'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brain', 'Brain', 'Immunology']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dicts[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The oldest method of studying the brain is anatomical, and until the middle of the 20th century, much of the progress in neuroscience came from the development of better cell stains and better microscopes. Neuroanatomists study the large-scale structure of the brain as well as the microscopic structure of neurons and their components, especially synapses. Among other tools, they employ a plethora of stains that reveal neural structure, chemistry, and connectivity. In recent years, the development of immunostaining techniques has allowed investigation of neurons that express specific sets of genes. Also, functional neuroanatomy uses medical imaging techniques to correlate variations',\n",
       " 'Neurophysiologists study the chemical, pharmacological, and electrical properties of the brain: their primary tools are drugs and recording devices. Thousands of experimentally developed drugs affect the nervous system, some in highly specific ways. Recordings of brain activity can be made using electrodes, either glued to the scalp as in EEG studies, or implanted inside the brains of animals for extracellular recordings, which can detect action potentials generated by individual neurons. Because the brain does not contain pain receptors, it is possible using these techniques to record brain activity from animals that are awake and behaving without causing distress. The same',\n",
       " 'Immunology is a branch of biomedical science that covers the study of immune systems in all organisms. It charts, measures, and contextualizes the: physiological functioning of the immune system in states of both health and diseases; malfunctions of the immune system in immunological disorders (such as autoimmune diseases, hypersensitivities, immune deficiency, and transplant rejection); the physical, chemical and physiological characteristics of the components of the immune system in vitro, in situ, and in vivo. Immunology has applications in numerous disciplines of medicine, particularly in the fields of organ transplantation, oncology, virology, bacteriology, parasitology, psychiatry, and dermatology.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dicts[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 55\t2684\t10758~10761 10760~10763\n",
    "# 55\t2685\t10762~10765 10764~10767\n",
    "# 71\t3484\t14230~14234 14232~14236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this = <Swig Object of type 'faiss::IndexHNSWFlat *' at 0x7f3d10336750>\n"
     ]
    }
   ],
   "source": [
    "for attr, val in index.__dict__.items():\n",
    "    print(f\"{attr} = {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-41c238f641ce>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-41c238f641ce>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    index.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_tensor(t, chunk_size):\n",
    "    return [t[i : i + chunk_size] for i in range(0, len(t), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = torch.ones((3, 2), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[1., 1.]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_tensor(ex, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
