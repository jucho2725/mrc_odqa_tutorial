{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "considerable-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, DPRConfig, DPRReaderOutput, DPRPretrainedReader, DPRReaderTokenizer\n",
    "from transformers.models.dpr.modeling_dpr import DPREncoder, DPR_READER_INPUTS_DOCSTRING, _CONFIG_FOR_DOC\n",
    "from transformers.file_utils import add_start_docstrings_to_model_forward, replace_return_docstrings\n",
    "from torch import Tensor, nn\n",
    "from typing import Optional, Union, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "canadian-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPRSpanPredictor(PreTrainedModel):\n",
    "\n",
    "    base_model_prefix = \"encoder\"\n",
    "\n",
    "    def __init__(self, config: DPRConfig):\n",
    "        super().__init__(config)\n",
    "        self.encoder = DPREncoder(config)\n",
    "        self.qa_outputs = nn.Linear(self.encoder.embeddings_size, 2)\n",
    "        self.qa_classifier = nn.Linear(self.encoder.embeddings_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Tensor,\n",
    "        attention_mask: Tensor,\n",
    "        inputs_embeds: Optional[Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "        output_hidden_states: bool = False,\n",
    "        return_dict: bool = False,\n",
    "    ) -> Union[DPRReaderOutput, Tuple[Tensor, ...]]:\n",
    "        # notations: N - number of questions in a batch, M - number of passages per questions, L - sequence length\n",
    "        n_passages, sequence_length = input_ids.size() if input_ids is not None else inputs_embeds.size()[:2]\n",
    "        # feed encoder\n",
    "        outputs = self.encoder(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        # compute logits\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        relevance_logits = self.qa_classifier(sequence_output[:, 0, :])\n",
    "\n",
    "        # resize\n",
    "        start_logits = start_logits.view(n_passages, sequence_length)\n",
    "        end_logits = end_logits.view(n_passages, sequence_length)\n",
    "        relevance_logits = relevance_logits.view(n_passages)\n",
    "\n",
    "        if not return_dict:\n",
    "            return (start_logits, end_logits, relevance_logits) + outputs[2:]\n",
    "\n",
    "        return DPRReaderOutput(\n",
    "            start_logits=start_logits,\n",
    "            end_logits=end_logits,\n",
    "            relevance_logits=relevance_logits,\n",
    "#             hidden_states=outputs.hidden_states,\n",
    "#             attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.encoder.init_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "lyric-label",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class DPRReader(DPRPretrainedReader):\n",
    "    def __init__(self, config: DPRConfig):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.span_predictor = DPRSpanPredictor(config)\n",
    "        self.init_weights()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(DPR_READER_INPUTS_DOCSTRING)\n",
    "    @replace_return_docstrings(output_type=DPRReaderOutput, config_class=_CONFIG_FOR_DOC)\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[Tensor] = None,\n",
    "        attention_mask: Optional[Tensor] = None,\n",
    "        inputs_embeds: Optional[Tensor] = None,\n",
    "        output_attentions: bool = None,\n",
    "        output_hidden_states: bool = None,\n",
    "        return_dict=None,\n",
    "    ) -> Union[DPRReaderOutput, Tuple[Tensor, ...]]:\n",
    "        r\"\"\"\n",
    "        Return:\n",
    "\n",
    "        Examples::\n",
    "\n",
    "            >>> from transformers import DPRReader, DPRReaderTokenizer\n",
    "            >>> tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "            >>> model = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "            >>> encoded_inputs = tokenizer(\n",
    "            ...         questions=[\"What is love ?\"],\n",
    "            ...         titles=[\"Haddaway\"],\n",
    "            ...         texts=[\"'What Is Love' is a song recorded by the artist Haddaway\"],\n",
    "            ...         return_tensors='pt'\n",
    "            ...     )\n",
    "            >>> outputs = model(**encoded_inputs)\n",
    "            >>> start_logits = outputs.stat_logits\n",
    "            >>> end_logits = outputs.end_logits\n",
    "            >>> relevance_logits = outputs.relevance_logits\n",
    "\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "\n",
    "        return self.span_predictor(\n",
    "            input_ids,\n",
    "            attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "exclusive-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DPRReaderTokenizer.from_pretrained(\"facebook/dpr-reader-single-nq-base\")\n",
    "model = DPRReader.from_pretrained(\"facebook/dpr-reader-single-nq-base\")\n",
    "\n",
    "encoded_inputs = tokenizer(\n",
    "    questions=\"What is love ?\",\n",
    "    titles=\"Haddaway\",\n",
    "    texts=\"What Is Love is a song recorded by the artist Haddaway\",\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "million-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "global_rng = random.Random()\n",
    "torch_device='cpu'\n",
    "def ids_tensor(shape, vocab_size, rng=None, name=None):\n",
    "    #  Creates a random int32 tensor of the shape within the vocab size\n",
    "    if rng is None:\n",
    "        rng = global_rng\n",
    "\n",
    "    total_dims = 1\n",
    "    for dim in shape:\n",
    "        total_dims *= dim\n",
    "\n",
    "    values = []\n",
    "    for _ in range(total_dims):\n",
    "        values.append(rng.randint(0, vocab_size - 1))\n",
    "\n",
    "    return torch.tensor(data=values, dtype=torch.long, device=torch_device).view(shape).contiguous()\n",
    "\n",
    "\n",
    "def random_attention_mask(shape, rng=None, name=None):\n",
    "    attn_mask = ids_tensor(shape, vocab_size=2, rng=None, name=None)\n",
    "    # make sure that at least one token is attended to for each batch\n",
    "    attn_mask[:, -1] = 1\n",
    "    return attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "exotic-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = random_attention_mask([1, 23]) # self.batch_size, self.seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "toxic-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs['attention_mask'] = attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "balanced-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2003, 2293, 1029,  102, 2018, 2850, 4576,  102, 2054, 2003,\n",
       "         2293, 2003, 1037, 2299, 2680, 2011, 1996, 3063, 2018, 2850, 4576]]), 'attention_mask': tensor([[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "purple-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**encoded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "mental-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPRReaderOutput(start_logits=tensor([[-3.0630, -4.7473, -5.8192, -5.6407, -5.8589, -9.0629, -4.9761, -6.8090,\n",
       "         -7.5950, -9.0560, -4.7091, -4.9144, -5.0070, -5.2773, -4.5161, -5.3637,\n",
       "         -4.3490, -4.1066, -1.6287, -2.3917,  1.7558, -5.2994, -2.0889]],\n",
       "       grad_fn=<ViewBackward>), end_logits=tensor([[-3.1214, -5.8755, -6.2211, -5.3107, -5.7220, -4.5273, -7.4018, -7.3266,\n",
       "         -5.7475, -4.5124, -4.2047, -5.1659, -3.1289, -6.3303, -4.7987, -5.4662,\n",
       "         -4.9542, -5.1752, -3.3463, -2.2221, -2.0111, -4.1174, -0.6945]],\n",
       "       grad_fn=<ViewBackward>), relevance_logits=tensor([-11.7683], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "broad-insulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3607e-03, 1.3659e-03, 4.6761e-04, 5.5902e-04, 4.4941e-04, 1.8246e-05,\n",
      "         1.0865e-03, 1.7380e-04, 7.9194e-05, 1.8373e-05, 1.4191e-03, 1.1558e-03,\n",
      "         1.0535e-03, 8.0394e-04, 1.7211e-03, 7.3742e-04, 2.0342e-03, 2.5923e-03,\n",
      "         3.0890e-02, 1.4403e-02, 9.1133e-01, 7.8641e-04, 1.9496e-02]],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "dist_start_logits = torch.softmax(outputs.start_logits, dim=1)\n",
    "print(dist_start_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dress-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "predicted_start_pos = torch.argmax(dist_start_logits, dim=1)\n",
    "print(predicted_start_pos.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-market",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
